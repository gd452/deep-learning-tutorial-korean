{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: RNN (Recurrent Neural Network) - 순차 데이터 처리\n",
    "\n",
    "RNN은 순차적인 데이터(텍스트, 시계열 등)를 처리하는 데 특화된 신경망입니다. 이전 정보를 기억하여 현재 예측에 활용합니다.\n",
    "\n",
    "## 학습 목표\n",
    "1. RNN의 기본 원리 이해\n",
    "2. Vanilla RNN, LSTM, GRU 구현\n",
    "3. 텍스트 생성 모델 만들기\n",
    "4. 감성 분석 수행하기\n",
    "5. 시계열 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "# 시드 설정\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN의 기본 개념\n",
    "\n",
    "RNN은 시간 단계별로 정보를 처리하며, 이전 상태를 다음 단계로 전달합니다.\n",
    "\n",
    "### 1.1 Vanilla RNN 직접 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNNCell(nn.Module):\n",
    "    \"\"\"단일 RNN 셀 구현\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)  # 입력 → 은닉\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size) # 은닉 → 은닉\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # h_t = tanh(W_ih * x_t + W_hh * h_{t-1} + b)\n",
    "        new_hidden = self.tanh(self.i2h(x) + self.h2h(hidden))\n",
    "        return new_hidden\n",
    "\n",
    "# RNN 셀 테스트\n",
    "rnn_cell = VanillaRNNCell(input_size=10, hidden_size=20)\n",
    "\n",
    "# 입력: (batch_size, input_size)\n",
    "x = torch.randn(32, 10)\n",
    "h = torch.randn(32, 20)\n",
    "\n",
    "new_h = rnn_cell(x, h)\n",
    "print(f\"입력 형태: {x.shape}\")\n",
    "print(f\"이전 은닉 상태: {h.shape}\")\n",
    "print(f\"새로운 은닉 상태: {new_h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 전체 RNN 레이어 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # PyTorch의 RNN 레이어 사용\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 초기 은닉 상태\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # RNN forward\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        # out: (batch, seq_len, hidden_size)\n",
    "        # hn: (num_layers, batch, hidden_size)\n",
    "        \n",
    "        return out, hn\n",
    "\n",
    "# RNN 테스트\n",
    "rnn = SimpleRNN(input_size=10, hidden_size=20, num_layers=2)\n",
    "\n",
    "# 시퀀스 입력: (batch_size, seq_len, input_size)\n",
    "seq_input = torch.randn(32, 15, 10)  # 32개 배치, 15 시간 단계, 10차원 입력\n",
    "\n",
    "output, hidden = rnn(seq_input)\n",
    "print(f\"입력 시퀀스 형태: {seq_input.shape}\")\n",
    "print(f\"출력 형태: {output.shape}\")\n",
    "print(f\"최종 은닉 상태 형태: {hidden.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM과 GRU\n",
    "\n",
    "기본 RNN의 장기 의존성 문제를 해결하기 위한 개선된 구조들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 변형들의 구조 비교\n",
    "class RNNComparison(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNNComparison, self).__init__()\n",
    "        \n",
    "        # 세 가지 RNN 타입\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (lstm_h, lstm_c) = self.lstm(x)\n",
    "        \n",
    "        # GRU\n",
    "        gru_out, _ = self.gru(x)\n",
    "        \n",
    "        return rnn_out, lstm_out, gru_out\n",
    "\n",
    "# 모델 생성 및 파라미터 수 비교\n",
    "comparison_model = RNNComparison(input_size=10, hidden_size=20)\n",
    "\n",
    "print(\"파라미터 수 비교:\")\n",
    "print(f\"RNN:  {sum(p.numel() for p in comparison_model.rnn.parameters()):,}\")\n",
    "print(f\"LSTM: {sum(p.numel() for p in comparison_model.lstm.parameters()):,}\")\n",
    "print(f\"GRU:  {sum(p.numel() for p in comparison_model.gru.parameters()):,}\")\n",
    "\n",
    "# LSTM의 게이트 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# RNN\n",
    "axes[0].text(0.5, 0.5, 'RNN\\n\\nh_t = tanh(W_ih·x_t + W_hh·h_{t-1})', \n",
    "             ha='center', va='center', fontsize=12, transform=axes[0].transAxes)\n",
    "axes[0].set_title('Vanilla RNN')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# LSTM\n",
    "axes[1].text(0.5, 0.7, 'LSTM', ha='center', va='center', fontsize=14, \n",
    "             weight='bold', transform=axes[1].transAxes)\n",
    "axes[1].text(0.5, 0.5, 'Forget Gate: f_t\\nInput Gate: i_t\\nOutput Gate: o_t\\nCell State: c_t', \n",
    "             ha='center', va='center', fontsize=10, transform=axes[1].transAxes)\n",
    "axes[1].set_title('Long Short-Term Memory')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# GRU\n",
    "axes[2].text(0.5, 0.6, 'GRU', ha='center', va='center', fontsize=14, \n",
    "             weight='bold', transform=axes[2].transAxes)\n",
    "axes[2].text(0.5, 0.4, 'Reset Gate: r_t\\nUpdate Gate: z_t', \n",
    "             ha='center', va='center', fontsize=10, transform=axes[2].transAxes)\n",
    "axes[2].set_title('Gated Recurrent Unit')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 문자 단위 텍스트 생성\n",
    "\n",
    "RNN을 사용하여 텍스트를 학습하고 생성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 텍스트 데이터\n",
    "text = \"\"\"Deep learning is a subset of machine learning in artificial intelligence.\n",
    "It has networks capable of learning unsupervised from data that is unstructured.\n",
    "Deep learning algorithms are similar to how nervous system structured.\n",
    "The deep learning models are trained by using large sets of labeled data.\"\"\"\n",
    "\n",
    "# 문자 집합 생성\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"텍스트 길이: {len(text)}\")\n",
    "print(f\"고유 문자 수: {vocab_size}\")\n",
    "print(f\"문자 집합: {''.join(chars)}\")\n",
    "\n",
    "# 텍스트를 인덱스로 변환\n",
    "data = [char_to_idx[ch] for ch in text]\n",
    "print(f\"\\n인코딩 예시: '{text[:20]}' → {data[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=2):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.2 if num_layers > 1 else 0)\n",
    "        \n",
    "        # 출력 레이어\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch, seq_len)\n",
    "        embed = self.embedding(x)  # (batch, seq_len, hidden_size)\n",
    "        \n",
    "        # LSTM forward\n",
    "        out, hidden = self.lstm(embed, hidden)\n",
    "        \n",
    "        # 출력 변환\n",
    "        out = self.fc(out)  # (batch, seq_len, vocab_size)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                weight.new_zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "\n",
    "# 모델 생성\n",
    "char_rnn = CharRNN(vocab_size, hidden_size=128, num_layers=2).to(device)\n",
    "print(\"Character RNN 모델:\")\n",
    "print(char_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 텍스트 생성을 위한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 준비\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        target = data[i+1:i+seq_length+1]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return torch.tensor(sequences), torch.tensor(targets)\n",
    "\n",
    "# 시퀀스 생성\n",
    "seq_length = 40\n",
    "X, y = create_sequences(data, seq_length)\n",
    "print(f\"학습 시퀀스 수: {len(X)}\")\n",
    "print(f\"시퀀스 형태: {X.shape}, 타겟 형태: {y.shape}\")\n",
    "\n",
    "# 데이터로더\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 학습\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(char_rnn.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 함수\n",
    "def train_char_rnn(model, dataloader, epochs=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        hidden = model.init_hidden(32)\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # Hidden state detach\n",
    "            hidden = tuple([h.detach() for h in hidden])\n",
    "            \n",
    "            # Forward\n",
    "            output, hidden = model(batch_x, hidden)\n",
    "            loss = criterion(output.view(-1, vocab_size), batch_y.view(-1))\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 학습 실행\n",
    "losses = train_char_rnn(char_rnn, dataloader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성 함수\n",
    "def generate_text(model, start_string, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    # 시작 문자열을 인덱스로 변환\n",
    "    input_eval = [char_to_idx[s] for s in start_string]\n",
    "    input_eval = torch.tensor(input_eval).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 생성된 텍스트 저장\n",
    "    text_generated = list(start_string)\n",
    "    \n",
    "    # 은닉 상태 초기화\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(length):\n",
    "            # 예측\n",
    "            output, hidden = model(input_eval, hidden)\n",
    "            \n",
    "            # 마지막 문자의 출력 사용\n",
    "            output = output[:, -1, :] / temperature\n",
    "            probabilities = F.softmax(output, dim=-1)\n",
    "            \n",
    "            # 샘플링\n",
    "            predicted_id = torch.multinomial(probabilities, 1).item()\n",
    "            \n",
    "            # 다음 입력 준비\n",
    "            input_eval = torch.tensor([[predicted_id]]).to(device)\n",
    "            \n",
    "            # 생성된 문자 추가\n",
    "            text_generated.append(idx_to_char[predicted_id])\n",
    "    \n",
    "    return ''.join(text_generated)\n",
    "\n",
    "# 다양한 온도로 텍스트 생성\n",
    "print(\"생성된 텍스트:\\n\")\n",
    "for temp in [0.5, 0.8, 1.0, 1.2]:\n",
    "    print(f\"\\nTemperature = {temp}:\")\n",
    "    generated = generate_text(char_rnn, \"Deep learning \", length=100, temperature=temp)\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 감성 분석 (Sentiment Analysis)\n",
    "\n",
    "영화 리뷰의 긍정/부정을 분류하는 모델을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 감성 분석 데이터셋\n",
    "reviews = [\n",
    "    (\"This movie is fantastic! Best film I've seen all year.\", 1),\n",
    "    (\"Terrible movie. Complete waste of time.\", 0),\n",
    "    (\"Amazing cinematography and great acting.\", 1),\n",
    "    (\"Boring plot and poor character development.\", 0),\n",
    "    (\"I loved every minute of this film!\", 1),\n",
    "    (\"One of the worst movies ever made.\", 0),\n",
    "    (\"Brilliant storytelling and excellent direction.\", 1),\n",
    "    (\"Fell asleep halfway through. Very disappointing.\", 0),\n",
    "    (\"A masterpiece! Highly recommend to everyone.\", 1),\n",
    "    (\"Predictable and unoriginal. Not worth watching.\", 0),\n",
    "]\n",
    "\n",
    "# 텍스트 전처리\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환 및 구두점 제거\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text.split()\n",
    "\n",
    "# 어휘 사전 구축\n",
    "all_words = []\n",
    "for review, _ in reviews:\n",
    "    all_words.extend(preprocess_text(review))\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "vocab = ['<PAD>', '<UNK>'] + [word for word, _ in word_counts.most_common()]\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"어휘 크기: {len(vocab)}\")\n",
    "print(f\"가장 빈번한 단어: {word_counts.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
    "                 n_layers=2, bidirectional=True, dropout=0.5):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                           bidirectional=bidirectional, dropout=dropout, \n",
    "                           batch_first=True)\n",
    "        \n",
    "        # 양방향 LSTM인 경우 hidden_dim * 2\n",
    "        fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text: (batch, seq_len)\n",
    "        embedded = self.embedding(text)  # (batch, seq_len, embedding_dim)\n",
    "        \n",
    "        # Pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, \n",
    "                                                           batch_first=True, \n",
    "                                                           enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        # 마지막 은닉 상태 사용\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        \n",
    "        # 분류\n",
    "        output = self.fc(hidden)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 모델 생성\n",
    "sentiment_model = SentimentRNN(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=256,\n",
    "    output_dim=1,\n",
    "    n_layers=2,\n",
    "    bidirectional=True,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "print(\"감성 분석 모델:\")\n",
    "print(sentiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 시계열 예측\n",
    "\n",
    "RNN을 사용하여 시계열 데이터를 예측해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사인파 데이터 생성\n",
    "def create_sine_wave_data(seq_length=50, num_samples=1000):\n",
    "    x = np.linspace(0, 100, num_samples)\n",
    "    y = np.sin(x) + 0.1 * np.random.randn(num_samples)  # 노이즈 추가\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(y) - seq_length):\n",
    "        seq = y[i:i+seq_length]\n",
    "        target = y[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# 데이터 생성\n",
    "X_time, y_time = create_sine_wave_data()\n",
    "print(f\"시계열 데이터 형태: {X_time.shape}\")\n",
    "print(f\"타겟 형태: {y_time.shape}\")\n",
    "\n",
    "# 학습/테스트 분할\n",
    "split_idx = int(0.8 * len(X_time))\n",
    "X_train = torch.FloatTensor(X_time[:split_idx]).unsqueeze(-1)\n",
    "y_train = torch.FloatTensor(y_time[:split_idx])\n",
    "X_test = torch.FloatTensor(X_time[split_idx:]).unsqueeze(-1)\n",
    "y_test = torch.FloatTensor(y_time[split_idx:])\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_time[:200], label='Sine Wave with Noise')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesRNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1):\n",
    "        super(TimeSeriesRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # GRU 사용\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                         batch_first=True, dropout=0.2 if num_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        out, _ = self.gru(x)\n",
    "        \n",
    "        # 마지막 시간 단계의 출력 사용\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "ts_model = TimeSeriesRNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ts_model.parameters(), lr=0.001)\n",
    "\n",
    "# 데이터로더\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 학습\n",
    "ts_model.train()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = ts_model(batch_x)\n",
    "        loss = criterion(output.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 및 시각화\n",
    "ts_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = ts_model(X_test.to(device)).cpu().numpy()\n",
    "\n",
    "# 결과 시각화\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# 학습 손실\n",
    "axes[0].plot(losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 예측 결과\n",
    "axes[1].plot(y_test[:100], label='Actual', alpha=0.7)\n",
    "axes[1].plot(test_pred[:100], label='Predicted', alpha=0.7)\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Time Series Prediction')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 예측 성능\n",
    "mse = np.mean((y_test.numpy() - test_pred.squeeze())**2)\n",
    "print(f\"\\nTest MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Attention 메커니즘\n",
    "\n",
    "시퀀스의 중요한 부분에 집중하는 어텐션 메커니즘을 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # Attention 가중치 계산\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # 출력 레이어\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM 출력\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq_len, hidden_size)\n",
    "        \n",
    "        # Attention 점수 계산\n",
    "        attention_scores = self.attention(lstm_out)  # (batch, seq_len, 1)\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch, seq_len, 1)\n",
    "        \n",
    "        # 가중 평균\n",
    "        weighted = lstm_out * attention_weights  # (batch, seq_len, hidden_size)\n",
    "        context = torch.sum(weighted, dim=1)  # (batch, hidden_size)\n",
    "        \n",
    "        # 출력\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "# Attention 시각화\n",
    "def visualize_attention(text, attention_weights):\n",
    "    fig, ax = plt.subplots(figsize=(10, 2))\n",
    "    \n",
    "    # 히트맵\n",
    "    im = ax.imshow(attention_weights.T, cmap='Blues', aspect='auto')\n",
    "    \n",
    "    # 텍스트 라벨\n",
    "    ax.set_xticks(range(len(text)))\n",
    "    ax.set_xticklabels(text, rotation=45)\n",
    "    ax.set_yticks([0])\n",
    "    ax.set_yticklabels(['Attention'])\n",
    "    \n",
    "    # 컬러바\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.title('Attention Weights')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 예시 실행\n",
    "attention_model = AttentionRNN(input_size=10, hidden_size=32, output_size=2)\n",
    "sample_input = torch.randn(1, 10, 10)  # (batch=1, seq_len=10, input_size=10)\n",
    "output, attn_weights = attention_model(sample_input)\n",
    "\n",
    "print(f\"출력 형태: {output.shape}\")\n",
    "print(f\"Attention 가중치 형태: {attn_weights.shape}\")\n",
    "\n",
    "# Attention 가중치 시각화\n",
    "sample_text = ['The', 'movie', 'was', 'really', 'good', 'and', 'I', 'enjoyed', 'it', '!']\n",
    "visualize_attention(sample_text, attn_weights[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 양방향 RNN과 다층 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 RNN 구조 비교\n",
    "class RNNArchitectures(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNArchitectures, self).__init__()\n",
    "        \n",
    "        # 1. 단방향 단층 RNN\n",
    "        self.simple_rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # 2. 양방향 RNN\n",
    "        self.bidirectional_rnn = nn.LSTM(input_size, hidden_size, \n",
    "                                        batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # 3. 다층 RNN\n",
    "        self.multilayer_rnn = nn.LSTM(input_size, hidden_size, \n",
    "                                     num_layers=3, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # 4. 양방향 다층 RNN\n",
    "        self.bidirectional_multilayer = nn.LSTM(input_size, hidden_size, \n",
    "                                               num_layers=3, batch_first=True, \n",
    "                                               bidirectional=True, dropout=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 각 구조의 출력\n",
    "        simple_out, _ = self.simple_rnn(x)\n",
    "        bi_out, _ = self.bidirectional_rnn(x)\n",
    "        multi_out, _ = self.multilayer_rnn(x)\n",
    "        bi_multi_out, _ = self.bidirectional_multilayer(x)\n",
    "        \n",
    "        return simple_out, bi_out, multi_out, bi_multi_out\n",
    "\n",
    "# 구조 비교\n",
    "architectures = RNNArchitectures(input_size=10, hidden_size=20, output_size=5)\n",
    "sample_input = torch.randn(2, 15, 10)  # (batch=2, seq_len=15, input_size=10)\n",
    "\n",
    "outputs = architectures(sample_input)\n",
    "print(\"다양한 RNN 구조의 출력 형태:\")\n",
    "print(f\"단방향 단층: {outputs[0].shape}\")\n",
    "print(f\"양방향 단층: {outputs[1].shape}\")\n",
    "print(f\"단방향 다층: {outputs[2].shape}\")\n",
    "print(f\"양방향 다층: {outputs[3].shape}\")\n",
    "\n",
    "# 파라미터 수 비교\n",
    "print(\"\\n파라미터 수:\")\n",
    "for name, module in architectures.named_children():\n",
    "    param_count = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name}: {param_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 연습 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1: Sequence-to-Sequence 모델 구현\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        # 힌트: Encoder와 Decoder 두 개의 RNN 필요\n",
    "        # Encoder: 입력 시퀀스를 고정 크기 벡터로 인코딩\n",
    "        # Decoder: 인코딩된 벡터를 출력 시퀀스로 디코딩\n",
    "        pass\n",
    "\n",
    "# 문제 2: 단어 단위 언어 모델 구현\n",
    "class WordLevelLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(WordLevelLM, self).__init__()\n",
    "        # 힌트: \n",
    "        # 1. 단어 임베딩\n",
    "        # 2. LSTM 레이어\n",
    "        # 3. 다음 단어 예측을 위한 출력층\n",
    "        pass\n",
    "\n",
    "# 문제 3: 다변량 시계열 예측\n",
    "# 여러 특징을 가진 시계열 데이터 처리\n",
    "def create_multivariate_data():\n",
    "    # 힌트: 여러 개의 관련된 시계열 생성\n",
    "    # 예: 온도, 습도, 기압 등\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 튜토리얼에서 배운 내용:\n",
    "1. RNN의 기본 원리와 구현\n",
    "2. LSTM과 GRU의 구조와 장점\n",
    "3. 문자 단위 텍스트 생성\n",
    "4. 감성 분석을 위한 텍스트 분류\n",
    "5. 시계열 데이터 예측\n",
    "6. Attention 메커니즘\n",
    "7. 양방향 및 다층 RNN 구조\n",
    "\n",
    "### RNN의 핵심 개념:\n",
    "- **순차적 정보 처리**: 이전 정보를 기억하여 현재 예측에 활용\n",
    "- **가변 길이 입력**: 다양한 길이의 시퀀스 처리 가능\n",
    "- **장기 의존성**: LSTM/GRU로 긴 시퀀스의 정보 보존\n",
    "- **양방향 처리**: 과거와 미래 정보 모두 활용\n",
    "\n",
    "축하합니다! 이제 딥러닝의 기초부터 CNN, RNN까지 모두 학습했습니다. \n",
    "다음 단계로는 Transformer, GAN, 강화학습 등 더 고급 주제들을 탐구해보세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}