{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: CNN (Convolutional Neural Network) - 이미지 인식의 핵심\n",
    "\n",
    "CNN은 이미지 처리에 특화된 신경망입니다. 이미지의 공간적 구조를 활용하여 효율적으로 특징을 추출합니다.\n",
    "\n",
    "## 학습 목표\n",
    "1. CNN의 핵심 구성 요소 이해 (Convolution, Pooling)\n",
    "2. 이미지 데이터 전처리와 증강\n",
    "3. CNN 아키텍처 설계\n",
    "4. MNIST 손글씨 숫자 분류\n",
    "5. CIFAR-10 컬러 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CNN의 핵심 개념\n",
    "\n",
    "### 1.1 Convolution 연산 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 2D Convolution 예제\n",
    "# 입력 이미지 (1채널, 5x5)\n",
    "input_image = torch.tensor([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 2, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, 5, 5)\n",
    "\n",
    "# 3x3 커널 (엣지 검출)\n",
    "kernel = torch.tensor([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, 3, 3)\n",
    "\n",
    "# Convolution 연산\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "conv.weight.data = kernel\n",
    "\n",
    "output = conv(input_image)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# 입력 이미지\n",
    "axes[0].imshow(input_image.squeeze(), cmap='gray')\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 커널\n",
    "axes[1].imshow(kernel.squeeze(), cmap='RdBu')\n",
    "axes[1].set_title('Kernel (Edge Detection)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 출력\n",
    "axes[2].imshow(output.squeeze().detach(), cmap='gray')\n",
    "axes[2].set_title('Output (Convolved)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks(range(5))\n",
    "    ax.set_yticks(range(5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pooling 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling 예제\n",
    "# 4x4 입력\n",
    "input_pool = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Max Pooling과 Average Pooling\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "max_output = max_pool(input_pool)\n",
    "avg_output = avg_pool(input_pool)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# 원본\n",
    "im1 = axes[0].imshow(input_pool.squeeze(), cmap='viridis')\n",
    "axes[0].set_title('Original (4x4)')\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[0].text(j, i, f'{int(input_pool[0, 0, i, j])}', \n",
    "                    ha='center', va='center', color='white')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Max Pooling\n",
    "im2 = axes[1].imshow(max_output.squeeze(), cmap='viridis')\n",
    "axes[1].set_title('Max Pooling (2x2)')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(j, i, f'{int(max_output[0, 0, i, j])}', \n",
    "                    ha='center', va='center', color='white')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Average Pooling\n",
    "im3 = axes[2].imshow(avg_output.squeeze(), cmap='viridis')\n",
    "axes[2].set_title('Average Pooling (2x2)')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[2].text(j, i, f'{avg_output[0, 0, i, j]:.1f}', \n",
    "                    ha='center', va='center', color='white')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST 데이터셋으로 시작하기\n",
    "\n",
    "MNIST는 0-9까지의 손글씨 숫자 이미지 데이터셋입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL Image → Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST 평균과 표준편차로 정규화\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋 다운로드\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"학습 데이터: {len(train_dataset)} 샘플\")\n",
    "print(f\"테스트 데이터: {len(test_dataset)} 샘플\")\n",
    "\n",
    "# 샘플 이미지 확인\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx in range(10):\n",
    "    image, label = train_dataset[idx]\n",
    "    axes[idx].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[idx].set_title(f'Label: {label}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 첫 번째 CNN 모델: LeNet-5 스타일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # 28x28x1 → 28x28x6\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)       # 28x28x6 → 14x14x6\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)            # 14x14x6 → 10x10x16\n",
    "        # 10x10x16 → 5x5x16 (after pooling)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # 10 classes\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Conv block 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # FC layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleCNN().to(device)\n",
    "print(\"모델 구조:\")\n",
    "print(model)\n",
    "\n",
    "# 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_epoch(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 학습 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 학습\n",
    "epochs = 10\n",
    "train_losses, test_losses = [], []\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion, epoch)\n",
    "    test_loss, test_acc = test_epoch(model, device, test_loader, criterion)\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 손실\n",
    "axes[0].plot(train_losses, label='Train Loss')\n",
    "axes[0].plot(test_losses, label='Test Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 정확도\n",
    "axes[1].plot(train_accs, label='Train Accuracy')\n",
    "axes[1].plot(test_accs, label='Test Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Test Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 예측 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 시각화\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 테스트 데이터에서 샘플 가져오기\n",
    "test_iter = iter(test_loader)\n",
    "images, labels = next(test_iter)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "for idx in range(15):\n",
    "    image = images[idx].squeeze()\n",
    "    true_label = labels[idx].item()\n",
    "    pred_label = predicted[idx].item()\n",
    "    \n",
    "    axes[idx].imshow(image, cmap='gray')\n",
    "    axes[idx].set_title(f'True: {true_label}, Pred: {pred_label}')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # 틀린 예측은 빨간색으로 표시\n",
    "    if true_label != pred_label:\n",
    "        axes[idx].set_title(f'True: {true_label}, Pred: {pred_label}', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 더 깊은 CNN: 현대적인 아키텍처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModernCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional blocks with batch normalization\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성\n",
    "modern_model = ModernCNN().to(device)\n",
    "print(\"현대적인 CNN 구조:\")\n",
    "print(modern_model)\n",
    "\n",
    "# 파라미터 수\n",
    "total_params = sum(p.numel() for p in modern_model.parameters())\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CIFAR-10: 컬러 이미지 분류\n",
    "\n",
    "이제 더 복잡한 32x32 컬러 이미지를 분류해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 데이터 전처리\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# CIFAR-10 데이터셋\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# 클래스 이름\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 샘플 이미지 시각화\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # 정규화 해제\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# 배치 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 이미지 보여주기\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx in range(16):\n",
    "    img = images[idx]\n",
    "    img = img / 2 + 0.5  # 정규화 해제\n",
    "    axes[idx].imshow(np.transpose(img, (1, 2, 0)))\n",
    "    axes[idx].set_title(classes[labels[idx]])\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 CIFAR-10을 위한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        \n",
    "        # VGG 스타일 블록\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성\n",
    "cifar_model = CIFAR10CNN().to(device)\n",
    "print(f\"CIFAR-10 CNN 파라미터 수: {sum(p.numel() for p in cifar_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 특징 시각화\n",
    "\n",
    "CNN이 학습한 특징들을 시각화해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(model):\n",
    "    # 첫 번째 컨볼루션 레이어의 필터 가져오기\n",
    "    first_conv_layer = None\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            first_conv_layer = module\n",
    "            break\n",
    "    \n",
    "    if first_conv_layer is None:\n",
    "        print(\"Conv2d 레이어를 찾을 수 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 필터 가중치 가져오기\n",
    "    filters = first_conv_layer.weight.data.cpu()\n",
    "    n_filters = min(filters.shape[0], 32)  # 최대 32개 필터만 표시\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        # 필터 정규화\n",
    "        filter_img = filters[i]\n",
    "        \n",
    "        # 단일 채널인 경우 (MNIST)\n",
    "        if filter_img.shape[0] == 1:\n",
    "            filter_img = filter_img.squeeze()\n",
    "            axes[i].imshow(filter_img, cmap='gray')\n",
    "        # 3채널인 경우 (CIFAR-10)\n",
    "        else:\n",
    "            filter_img = filter_img.permute(1, 2, 0)\n",
    "            # 정규화\n",
    "            filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min())\n",
    "            axes[i].imshow(filter_img)\n",
    "        \n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Filter {i}')\n",
    "    \n",
    "    # 남은 subplot 숨기기\n",
    "    for i in range(n_filters, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# MNIST 모델의 필터 시각화\n",
    "print(\"MNIST CNN의 첫 번째 레이어 필터:\")\n",
    "visualize_filters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 중간 레이어 활성화 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activations(model, input_image, target_layers=None):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    \n",
    "    # Hook 함수 정의\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output)\n",
    "    \n",
    "    # Hook 등록\n",
    "    hooks = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            hook = module.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model(input_image.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Hook 제거\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    # 활성화 시각화\n",
    "    fig, axes = plt.subplots(len(activations), 8, figsize=(16, 2*len(activations)))\n",
    "    if len(activations) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for layer_idx, activation in enumerate(activations):\n",
    "        act = activation[0].cpu()  # 첫 번째 샘플\n",
    "        n_channels = min(act.shape[0], 8)  # 최대 8개 채널만 표시\n",
    "        \n",
    "        for ch_idx in range(n_channels):\n",
    "            axes[layer_idx, ch_idx].imshow(act[ch_idx], cmap='viridis')\n",
    "            axes[layer_idx, ch_idx].axis('off')\n",
    "            if ch_idx == 0:\n",
    "                axes[layer_idx, ch_idx].set_ylabel(f'Conv {layer_idx+1}', rotation=0, labelpad=40)\n",
    "        \n",
    "        # 남은 subplot 숨기기\n",
    "        for ch_idx in range(n_channels, 8):\n",
    "            axes[layer_idx, ch_idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Layer Activations', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 테스트 이미지로 활성화 시각화\n",
    "test_image, test_label = test_dataset[0]\n",
    "print(f\"테스트 이미지 레이블: {test_label}\")\n",
    "\n",
    "# 원본 이미지 표시\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(test_image.squeeze(), cmap='gray')\n",
    "plt.title(f'Input Image (Label: {test_label})')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 활성화 시각화\n",
    "visualize_activations(model, test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 전이 학습 (Transfer Learning)\n",
    "\n",
    "사전 학습된 모델을 활용하여 적은 데이터로도 좋은 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 ResNet 모델 불러오기\n",
    "import torchvision.models as models\n",
    "\n",
    "# ResNet18 모델 (ImageNet으로 사전 학습됨)\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(\"ResNet18 구조 (마지막 부분):\")\n",
    "print(list(resnet.children())[-2:])\n",
    "\n",
    "# CIFAR-10을 위해 마지막 층 수정\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features, 10)  # 10개 클래스\n",
    "\n",
    "# 특징 추출기로 사용 (conv 레이어는 고정)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 층만 학습 가능하게\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"\\n학습 가능한 파라미터 수: {sum(p.numel() for p in resnet.parameters() if p.requires_grad):,}\")\n",
    "print(f\"전체 파라미터 수: {sum(p.numel() for p in resnet.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 데이터 증강 (Data Augmentation) 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 데이터 증강 기법\n",
    "augmentation_transforms = [\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "]\n",
    "\n",
    "# 원본 이미지\n",
    "original_transform = transforms.Compose([transforms.ToTensor()])\n",
    "original_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=original_transform)\n",
    "original_image, label = original_dataset[0]\n",
    "\n",
    "# 증강된 이미지들 생성\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 원본 이미지\n",
    "axes[0].imshow(np.transpose(original_image.numpy(), (1, 2, 0)))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 증강된 이미지들\n",
    "for i, aug_transform in enumerate(augmentation_transforms, 1):\n",
    "    augmented_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        aug_transform,\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # 같은 증강을 두 번 적용\n",
    "    for j in range(2):\n",
    "        idx = i + j * 5\n",
    "        if idx < len(axes):\n",
    "            augmented = augmented_transform(original_image)\n",
    "            axes[idx].imshow(np.transpose(augmented.numpy(), (1, 2, 0)))\n",
    "            axes[idx].set_title(aug_transform.__class__.__name__)\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(f'Data Augmentation Examples (Class: {classes[label]})', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 연습 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1: Residual Block 구현\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 힌트: \n",
    "        # 1. 두 개의 3x3 conv 레이어\n",
    "        # 2. BatchNorm과 ReLU\n",
    "        # 3. skip connection을 위한 shortcut\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 힌트: out = F.relu(residual + shortcut)\n",
    "        pass\n",
    "\n",
    "# 문제 2: Inception Module 구현\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, out_3x3, out_5x5, out_pool):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        # 힌트: 서로 다른 크기의 conv를 병렬로 수행하고 concatenate\n",
    "        pass\n",
    "\n",
    "# 문제 3: Attention 메커니즘 추가\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        # 힌트: Global Average Pooling → FC → ReLU → FC → Sigmoid\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 튜토리얼에서 배운 내용:\n",
    "1. CNN의 핵심 구성 요소 (Convolution, Pooling)\n",
    "2. MNIST 손글씨 숫자 분류\n",
    "3. 현대적인 CNN 아키텍처 설계\n",
    "4. CIFAR-10 컬러 이미지 분류\n",
    "5. 특징 시각화와 해석\n",
    "6. 전이 학습\n",
    "7. 데이터 증강\n",
    "\n",
    "### CNN의 핵심 개념:\n",
    "- **지역적 연결성**: 각 뉴런이 입력의 일부분만 봄\n",
    "- **가중치 공유**: 같은 필터를 이미지 전체에 적용\n",
    "- **계층적 특징 학습**: 낮은 층은 엣지, 높은 층은 복잡한 패턴\n",
    "- **이동 불변성**: 객체가 이미지의 어디에 있어도 인식\n",
    "\n",
    "다음 단계에서는 RNN을 사용하여 순차 데이터를 처리하는 방법을 배워보겠습니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}